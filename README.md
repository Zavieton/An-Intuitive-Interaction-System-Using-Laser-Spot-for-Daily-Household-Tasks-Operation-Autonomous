# An Intuitive Interaction System Using Laser Spot for Daily Household Tasks Operation Autonomous

this repo is some details of our paper *An Intuitive Interaction System Using Laser Spot for Daily Household Tasks Operation Autonomous* published on ICIRA 2021.

### Environments： Env_Config.ipynb
### Paper and Experiments： https://link.springer.com/chapter/10.1007/978-3-030-89134-3_25
### Videos： https://www.youtube.com/watch?v=YLUohr3KlCg&list=LL&index=2

## Abstract 
The Wheelchair Mounted Robotic Arm (WMRA) can help the elderly
and handicapped to complete some household tasks independently, while due to
the mobility of these people are limited, they cannot complete household tasks
easily through the interactions that need frequent operations such as using handles.
If the tasks are completed automatically and users only need to send commands
by gestures or EEG. The user will lose involvement and adaptability to the environment. In this paper, we propose a method named laser intuitive interaction, it
can analyze the user’s intention by identifying the semantic information of the
laser and assemble actions to complete unstructured tasks. Firstly, the household
tasks are summarized base on the International Classification of Functionality,
Disability and Health (ICF) and the laser semantics are designed according to the
daily household tasks; Secondly, the method of laser semantic detection base on
SVM is discussed; Finally, the information of the laser semantic and the action
of the robotic arm are integrated into the ROS. The results of the experiment on
daily household tasks show that the accuracy of laser semantic detection is above
92%, the number and time of laser interaction are 33% and 75% of the handle
interaction.

![image](https://github.com/Zavieton/An-Intuitive-Interaction-System-Using-Laser-Spot-for-Daily-Household-Tasks-Operation-Autonomous/blob/main/wmra_system.png)
